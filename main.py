import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import koreanize_matplotlib # í•œê¸€ í°íŠ¸ ì„¤ì •ì„ ìœ„í•´ ì‚¬ìš©
import numpy as np # í˜¼ë™ í–‰ë ¬ ì‹œê°í™”ë¥¼ ìœ„í•´ numpy ì¶”ê°€ (ì˜¤ë¥˜ ìˆ˜ì •)

# í•œê¸€ í°íŠ¸ ì„¤ì • ì ìš©
koreanize_matplotlib.use_font()

# --- ë°ì´í„° ë¡œë“œ ë° ëª¨ë¸ í•™ìŠµ í•¨ìˆ˜ (ìºì‹± ì ìš©) ---
# Streamlitì˜ @st.cache_data ë°ì½”ë ˆì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„° ë¡œë“œ ë° í•™ìŠµëœ ëª¨ë¸ì„ ìºì‹±í•©ë‹ˆë‹¤.
# ì´ë ‡ê²Œ í•˜ë©´ ì•±ì´ ë‹¤ì‹œ ì‹¤í–‰ë  ë•Œë§ˆë‹¤(ì˜ˆ: ìœ„ì ¯ ìƒí˜¸ ì‘ìš© ì‹œ) ì‹œê°„ì´ ë§ì´ ê±¸ë¦¬ëŠ”
# ë°ì´í„° ë¡œë“œ ë° ëª¨ë¸ í•™ìŠµ ë‹¨ê³„ë¥¼ ë‹¤ì‹œ ì‹¤í–‰í•˜ëŠ” ê²ƒì„ ë°©ì§€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
@st.cache_data
def load_data():
    # ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” íŒŒì¼ì„ Streamlit ì•±ê³¼ ê°™ì€ ë””ë ‰í† ë¦¬ì— ë‘ê±°ë‚˜,
    # ì‚¬ìš©ìì—ê²Œ ì—…ë¡œë“œí•˜ë„ë¡ í•˜ëŠ” ë“±ì˜ ë°©ë²•ì„ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.
    # ì´ ì˜ˆì œì—ì„œëŠ” íŒŒì¼ì´ ì•± ì‹¤í–‰ ê²½ë¡œì— ìˆë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤.
    try:
        df = pd.read_csv("earthquake_data_tsunami.csv")
        return df
    except FileNotFoundError:
        st.error("ğŸš¨ 'earthquake_data_tsunami.csv' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ì„ ì•±ê³¼ ê°™ì€ ë””ë ‰í† ë¦¬ì— ë„£ì–´ì£¼ì„¸ìš”.")
        return None

@st.cache_resource
def train_model(df):
    if df is None:
        return None, None, None

    # STEP 3. í•„ìš”í•œ ì—´ ì„ íƒ
    X = df[["magnitude", "depth", "latitude", "longitude"]]    # ì…ë ¥ ë³€ìˆ˜
    y = df["tsunami"]  # ëª©í‘œ ë³€ìˆ˜

    # STEP 4. í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„ë¦¬
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # STEP 5. ëª¨ë¸ í•™ìŠµ
    model = RandomForestClassifier(n_estimators=100, random_state=42)
    model.fit(X_train, y_train)

    return model, X_test, y_test

# --- Streamlit ì•± êµ¬ì„± ì‹œì‘ ---
def main():
    st.set_page_config(page_title="ì“°ë‚˜ë¯¸ ë°œìƒ ì˜ˆì¸¡ ëª¨ë¸ (Random Forest)")
    st.title("ğŸŒŠ ì§€ì§„ ë°ì´í„° ê¸°ë°˜ ì“°ë‚˜ë¯¸ ë°œìƒ ì˜ˆì¸¡ ë¶„ì„")
    st.markdown("---")

    # 1. ë°ì´í„° ë¡œë“œ ë° ëª¨ë¸ í•™ìŠµ
    df = load_data()
    if df is None:
        return

    model, X_test, y_test = train_model(df)
    if model is None:
        return

    # 2. ì˜ˆì¸¡ ê¸°ëŠ¥ ì„¹ì…˜
    ## ì˜ˆì¸¡ ì‚¬ì´ë“œë°”
    st.sidebar.header("ğŸ—ºï¸ ì˜ˆì¸¡ ë³€ìˆ˜ ì…ë ¥")
    st.sidebar.write("ì“°ë‚˜ë¯¸ ë°œìƒ ì—¬ë¶€ë¥¼ ì˜ˆì¸¡í•˜ê¸° ìœ„í•œ ì§€ì§„ì˜ íŠ¹ì„±ì„ ì…ë ¥í•˜ì„¸ìš”.")

    # ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
    # ë°ì´í„°í”„ë ˆì„ì´ ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸ í›„ min/max ê°’ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
    if not df.empty:
      magnitude_min = float(df['magnitude'].min())
      magnitude_max = float(df['magnitude'].max())
      depth_min = float(df['depth'].min())
      depth_max = float(df['depth'].max())
      latitude_min = float(df['latitude'].min())
      latitude_max = float(df['latitude'].max())
      longitude_min = float(df['longitude'].min())
      longitude_max = float(df['longitude'].max())
    else: # ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš°ë¥¼ ëŒ€ë¹„í•œ ê¸°ë³¸ê°’
      magnitude_min, magnitude_max = 0.0, 10.0
      depth_min, depth_max = 0.0, 1000.0
      latitude_min, latitude_max = -90.0, 90.0
      longitude_min, longitude_max = -180.0, 180.0

    magnitude = st.sidebar.slider("ì§„ë„ (Magnitude)", magnitude_min, magnitude_max, 5.0)
    depth = st.sidebar.slider("ê¹Šì´ (Depth, km)", depth_min, depth_max, 50.0)
    latitude = st.sidebar.number_input("ìœ„ë„ (Latitude)", latitude_min, latitude_max, 35.0, step=0.01)
    longitude = st.sidebar.number_input("ê²½ë„ (Longitude)", longitude_min, longitude_max, 130.0, step=0.01)

    # ì˜ˆì¸¡ ë²„íŠ¼
    if st.sidebar.button("ì“°ë‚˜ë¯¸ ì˜ˆì¸¡ ì‹¤í–‰"):
        # ì…ë ¥ ë°ì´í„°ë¥¼ DataFrame í˜•íƒœë¡œ ë³€í™˜
        input_data = pd.DataFrame([[magnitude, depth, latitude, longitude]],
                                     columns=["magnitude", "depth", "latitude", "longitude"])

        # ì˜ˆì¸¡ ìˆ˜í–‰
        prediction = model.predict(input_data)[0]
        prediction_proba = model.predict_proba(input_data)

        st.subheader("ğŸ“Š ì˜ˆì¸¡ ê²°ê³¼")
        if prediction == 1:
            st.success("## âš ï¸ ì“°ë‚˜ë¯¸ **ë°œìƒ ì˜ˆì¸¡**!")
            st.write(f"**ì“°ë‚˜ë¯¸ ë°œìƒ í™•ë¥ :** **{prediction_proba[0][1]*100:.2f}%**")
        else:
            st.info("## âœ… ì“°ë‚˜ë¯¸ **ë¯¸ë°œìƒ ì˜ˆì¸¡**")
            st.write(f"**ì“°ë‚˜ë¯¸ ë¯¸ë°œìƒ í™•ë¥ :** **{prediction_proba[0][0]*100:.2f}%**")

        st.markdown("---")


    # 3. ëª¨ë¸ ë¶„ì„ ì„¹ì…˜ (íƒ­ êµ¬ì„±)
    st.header("ğŸ”¬ ëª¨ë¸ ì„±ëŠ¥ ë° ë¶„ì„")
    tab1, tab2, tab3 = st.tabs(["ëª¨ë¸ ì„±ëŠ¥ ì§€í‘œ", "íŠ¹ì„± ì¤‘ìš”ë„ ì‹œê°í™”", "ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°"])

    with tab1:
        st.subheader("ëª¨ë¸ í‰ê°€ ê²°ê³¼")
        if model and X_test is not None:
            # STEP 6. ì˜ˆì¸¡ ë° í‰ê°€
            y_pred = model.predict(X_test)
            accuracy = accuracy_score(y_test, y_pred)
            report = classification_report(y_test, y_pred, output_dict=True)
            cm = confusion_matrix(y_test, y_pred)

            st.metric("í…ŒìŠ¤íŠ¸ ë°ì´í„° ì •í™•ë„ (Accuracy)", f"{accuracy*100:.2f}%")

            st.markdown("**ë¶„ë¥˜ ë¦¬í¬íŠ¸ (Classification Report)**")
            st.dataframe(pd.DataFrame(report).transpose())

            st.markdown("**í˜¼ë™ í–‰ë ¬ (Confusion Matrix)**")
            # í˜¼ë™ í–‰ë ¬ ì‹œê°í™”
            fig, ax = plt.subplots()
            cax = ax.matshow(cm, cmap=plt.cm.Blues)
            plt.title('í˜¼ë™ í–‰ë ¬', y=1.1)
            fig.colorbar(cax)
            ax.set_xticklabels([''] + [0, 1])
            ax.set_yticklabels([''] + [0, 1])
            plt.xlabel('ì˜ˆì¸¡ ê°’ (Predicted)')
            plt.ylabel('ì‹¤ì œ ê°’ (Actual)')
            for (i, j), val in np.ndenumerate(cm):
                ax.text(j, i, f'{val}', ha='center', va='center', color='red' if i == j else 'black')
            st.pyplot(fig)
            
            st.markdown("> **ë ˆì´ë¸”:** '0'ì€ ì“°ë‚˜ë¯¸ ë¯¸ë°œìƒ, '1'ì€ ì“°ë‚˜ë¯¸ ë°œìƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.")


    with tab2:
        st.subheader("íŠ¹ì„± ì¤‘ìš”ë„ ì‹œê°í™”")
        # STEP 7. ì¤‘ìš” ë³€ìˆ˜ ì‹œê°í™”
        importances = model.feature_importances_
        feature_names = X_test.columns

        # Matplotlibì„ ì‚¬ìš©í•˜ì—¬ ì‹œê°í™”
        fig, ax = plt.subplots()
        ax.bar(feature_names, importances)
        ax.set_title("Feature Importance (íŠ¹ì„±ì´ ì“°ë‚˜ë¯¸ ì˜ˆì¸¡ì— ë¯¸ì¹˜ëŠ” ì˜í–¥)")
        ax.set_ylabel("ì¤‘ìš”ë„")
        ax.tick_params(axis='x', rotation=45)
        plt.tight_layout()
        st.pyplot(fig) # Streamlitì— Matplotlib ì°¨íŠ¸ í‘œì‹œ 


    with tab3:
        st.subheader("ë°ì´í„°ì…‹ ë¯¸ë¦¬ë³´ê¸°")
        st.write(df.head())
        st.write(f"**ì „ì²´ ë°ì´í„° í¬ê¸°:** {df.shape[0]} í–‰, {df.shape[1]} ì—´")
        st.write("**ì»¬ëŸ¼ ì„¤ëª…:**")
        st.markdown(
            """
            * `magnitude`: ì§„ë„ (ì§€ì§„ì˜ í¬ê¸°)
            * `depth`: ê¹Šì´ (ì§€ì§„ ë°œìƒ ê¹Šì´, km)
            * `latitude`: ìœ„ë„
            * `longitude`: ê²½ë„
            * `tsunami`: ì“°ë‚˜ë¯¸ ë°œìƒ ì—¬ë¶€ (0: ë¯¸ë°œìƒ, 1: ë°œìƒ)
            """
        )

if __name__ == "__main__":
    main()
    
